{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "499cff714e604be89bec523a3ca470f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd2f3d8747644583912496275bf35e97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a0a9758240c4f59832234d789e79947",
              "IPY_MODEL_4a70a80b98a2437d907b7a3a30f2535b"
            ]
          }
        },
        "fd2f3d8747644583912496275bf35e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a0a9758240c4f59832234d789e79947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12f64434b7bb43a782ea06df22a46453",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf0a7f412da944448d89a4cfc118affb"
          }
        },
        "4a70a80b98a2437d907b7a3a30f2535b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b1714f9b863c45859e7280b6a85eae40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 90385734.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54586449cd2d4ce9a9c9795cacdbe9a0"
          }
        },
        "12f64434b7bb43a782ea06df22a46453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf0a7f412da944448d89a4cfc118affb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1714f9b863c45859e7280b6a85eae40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54586449cd2d4ce9a9c9795cacdbe9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvishrantsSh/Electrothon_3.0/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA--s2tNnfux"
      },
      "source": [    "**TEAM ENIGMA**\n",
        "\nThis file contains the different approaches we tried in this project.\n",
        "We mainly focused on two major frameworks:\n",
        "1. **Tensorflow**\n",
        "2. **PyTorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_daHeMcm9bY"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from cv2 import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZMO9sEmBdoV"
      },
      "source": [
        "def conv_2d_layer(self,new_input,filter_shape,activate=tf.identity,stride=1,padding='SAME',name=None):\r\n",
        "        with tf.variable_scope(name):\r\n",
        "            W = tf.get_variable(\"W\",shape=filter_shape,initializer=tf.random_normal_initializer(0., 0.005))\r\n",
        "            b = tf.get_variable(\"b\",shape=filter_shape[-1],initializer=tf.constant_initializer(0.))\r\n",
        "            conv = tf.nn.conv2d(input=new_input,filters=w,strides=[1,stride,stride,1], padding=padding)\r\n",
        "            bias = activate(tf.nn.bias_add(value=conv,bias=b))\r\n",
        "        return bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZJAJfXWhmC-"
      },
      "source": [
        "def deconv_2d_layer(self,new_input,filter_shape,output_shape,activate=tf.identity,stride=1,padding='SAME',name=None):\r\n",
        "        with tf.variable_scope(name):\r\n",
        "            W = tf.get_variable(\"W\",shape=filter_shape,initializer=tf.random_normal_initializer(0., 0.005))\r\n",
        "            b = tf.get_variable(\"b\",shape=filter_shape[-2],initializer=tf.constant_initializer(0.))\r\n",
        "            deconv = tf.nn.conv2d_transpose(input=new_input,filters=W,output_shape=output_shape,strides=[1,stride,stride,1], padding=padding)\r\n",
        "            bias = activate(tf.nn.bias_add(value=deconv,bias=b))\r\n",
        "        return bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkSpJqfRk0X-"
      },
      "source": [
        "def new_fc_layer(self,new_input,output_size,name):\r\n",
        "        shape = new_input.get_shape().as_list()\r\n",
        "        dim = np.prod(shape[1:])\r\n",
        "        x = tf.reshape(bottom,[-1, dim])\r\n",
        "        input_size = dim\r\n",
        "        with tf.variable_scope(name):\r\n",
        "            W = tf.get_variable(\"W\",shape=[input_size, output_size],initializer=tf.random_normal_initializer(0., 0.005))\r\n",
        "            b = tf.get_variable(\"b\",shape=[output_size],initializer=tf.constant_initializer(0.))\r\n",
        "            fc = tf.nn.bias_add(value=tf.matmul(x,W),bias=b)\r\n",
        "        return fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SzkxvyFltdP"
      },
      "source": [
        "def channel_fc_layer(self, input, name):\r\n",
        "        _,width,height,n_feat_map = input.get_shape().as_list()\r\n",
        "        input_reshape = tf.reshape( input, [-1, width*height, n_feat_map] )\r\n",
        "        input_transpose = tf.transpose( input_reshape, [2,0,1] )\r\n",
        "        with tf.variable_scope(name):\r\n",
        "            W = tf.get_variable(\"W\",shape=[n_feat_map,width*height, width*height],initializer=tf.random_normal_initializer(0., 0.005))\r\n",
        "            output = tf.batch_matmul(input_transpose, W)\r\n",
        "        output_transpose = tf.transpose(output, [1,2,0])\r\n",
        "        output_reshape = tf.reshape(output_transpose,[-1, height, width, n_feat_map])\r\n",
        "        return output_reshape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IDkV7fFmrjl"
      },
      "source": [
        " def leaky_relu_func(self,new_input):\r\n",
        "        return tf.nn.leaky_relu(new_input,alpha=0.1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUdZWgFznJp8"
      },
      "source": [
        "def batch_norm(self, new_input, is_train, var_epsilon=1e-8, name=None):\r\n",
        "        new_input = tf.clip_by_value( new_input, -100., 100.)\r\n",
        "        depth = new_input.get_shape().as_list()[-1]\r\n",
        "        with tf.variable_scope(name):\r\n",
        "            gamma = tf.get_variable(\"gamma\",shape=[depth],initializer=tf.constant_initializer(1.))\r\n",
        "            beta  = tf.get_variable(\"beta\",shape=[depth],initializer=tf.constant_initializer(0.))\r\n",
        "            batch_mean, batch_var = tf.nn.moments(new_input, [0,1,2], name='moments')\r\n",
        "            exp_ma = tf.train.ExponentialMovingAverage(decay=0.5)\r\n",
        "\r\n",
        "            def update():\r\n",
        "                with tf.control_dependencies([exp_ma_op]):\r\n",
        "                    return tf.identity(batch_mean), tf.identity(batch_var)\r\n",
        "\r\n",
        "            exp_ma_op = exp_ma.apply([batch_mean, batch_var])\r\n",
        "            exp_ma_mean, exp_ma_var = exp_ma.average(batch_mean), exp_ma.average(batch_var)\r\n",
        "            mean, var = tf.cond(is_train,update,lambda:(exp_ma_mean, exp_ma_var) )\r\n",
        "\r\n",
        "            normed = tf.nn.batch_normalization(new_input,mean=mean,variance=var,offset=beta,scale=gamma,variance_epsilon=epsilon)\r\n",
        "        return normed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGGoEGPMstIz"
      },
      "source": [
        "def resize_conv_2d_layer(self, new_input, filter_shape, resize_scale=2, activation=tf.identity, padding='SAME', stride=1, name=None):\r\n",
        "        width = new_input.get_shape().as_list()[1]\r\n",
        "        height = new_input.get_shape().as_list()[2]\r\n",
        "        new_input = tf.raw_ops.ResizeNearestNeighbor(new_input,size=[width*resize_scale, height*resize_scale])\r\n",
        "        bias = self.conv_2d_layer(new_input, filter_shape, stride=1,name=name )\r\n",
        "        return bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EvqqHhksxF_"
      },
      "source": [
        "def generator( self, images, is_train ):  \r\n",
        "        with tf.variable_scope('GEN'):\r\n",
        "            conv1_1 = self.new_conv_layer(images, [3,3,3,32], stride=1, name=\"conv1_1\" )\r\n",
        "            conv1_1 = tf.nn.elu(conv1_1)\r\n",
        "            conv1_2 = self.new_conv_layer(conv1_1, [3,3,32,32], stride=1, name=\"conv1_2\" ) \r\n",
        "            conv1_2 = tf.nn.elu(conv1_2)\r\n",
        "            conv1_stride = self.new_conv_layer(conv1_2, [3,3,32,32], stride=2, name=\"conv1_stride\")\r\n",
        "            conv2_1 = self.new_conv_layer(conv1_stride, [3,3,32,64], stride=1, name=\"conv2_1\" ) \r\n",
        "            conv2_1 = tf.nn.elu(conv2_1)\r\n",
        "            conv2_2 = self.new_conv_layer(conv2_1, [3,3,64, 64], stride=1, name=\"conv2_2\" )\r\n",
        "            conv2_2 = tf.nn.elu(conv2_2)\r\n",
        "            conv2_stride = self.new_conv_layer(conv2_2, [3,3,64,64], stride=2, name=\"conv2_stride\")\r\n",
        "            conv3_1 = self.new_conv_layer(conv2_stride, [3,3,64,128], stride=1, name=\"conv3_1\" ) \r\n",
        "            conv3_1 = tf.nn.elu(conv3_1)\r\n",
        "            conv3_2 = self.new_conv_layer(conv3_1, [3,3,128, 128], stride=1, name=\"conv3_2\" ) \r\n",
        "            conv3_2 = tf.nn.elu(conv3_2)\r\n",
        "            conv3_3 = self.new_conv_layer(conv3_2, [3,3,128,128], stride=1, name=\"conv3_3\" ) \r\n",
        "            conv3_3 = tf.nn.elu(conv3_3)\r\n",
        "            conv3_4 = self.new_conv_layer(conv3_3, [3,3,128, 128], stride=1, name=\"conv3_4\" )    \r\n",
        "            conv3_4 = tf.nn.elu(conv3_4)\r\n",
        "            conv3_stride = self.new_conv_layer(conv3_4, [3,3,128,128], stride=2, name=\"conv3_stride\") \r\n",
        "            \r\n",
        "            conv4_stride = self.new_conv_layer(conv3_stride, [3,3,128,128], stride=2, name=\"conv4_stride\")\r\n",
        "            conv4_stride = tf.nn.elu(conv4_stride)\r\n",
        "            \r\n",
        "            conv5_stride = self.new_conv_layer(conv4_stride, [3,3,128,128], stride=2, name=\"conv5_stride\")\r\n",
        "            conv5_stride = tf.nn.elu(conv5_stride)\r\n",
        "            \r\n",
        "            conv6_stride = self.new_conv_layer(conv5_stride, [3,3,128,128], stride=2, name=\"conv6_stride\")\r\n",
        "            conv6_stride = tf.nn.elu(conv6_stride)\r\n",
        "\r\n",
        "            deconv5_fs = self.new_deconv_layer( conv6_stride, [3,3,128,128], conv5_stride.get_shape().as_list(), stride=2, name=\"deconv5_fs\")\r\n",
        "            debn5_fs = tf.nn.elu(deconv5_fs)\r\n",
        "            \r\n",
        "            skip5 = tf.concat([debn5_fs, conv5_stride], 3)\r\n",
        "            channels5 = skip5.get_shape().as_list()[3]\r\n",
        "  \r\n",
        "            deconv4_fs = self.new_deconv_layer( skip5, [3,3,128,channels5], conv4_stride.get_shape().as_list(), stride=2, name=\"deconv4_fs\")\r\n",
        "            debn4_fs = tf.nn.elu(deconv4_fs)\r\n",
        "            \r\n",
        "            skip4 = tf.concat([debn4_fs, conv4_stride], 3)\r\n",
        "            channels4 = skip4.get_shape().as_list()[3]\r\n",
        " \r\n",
        "            deconv3_fs = self.new_deconv_layer( skip4, [3,3,128,channels4], conv3_stride.get_shape().as_list(), stride=2, name=\"deconv3_fs\")\r\n",
        "            debn3_fs = tf.nn.elu(deconv3_fs)\r\n",
        "            \r\n",
        "            skip3 = tf.concat([debn3_fs, conv3_stride], 3)\r\n",
        "            channels3 = skip3.get_shape().as_list()[3]\r\n",
        "   \r\n",
        "            deconv2_fs = self.new_deconv_layer( skip3, [3,3,64,channels3], conv2_stride.get_shape().as_list(), stride=2, name=\"deconv2_fs\")\r\n",
        "            debn2_fs = tf.nn.elu(deconv2_fs)\r\n",
        "            \r\n",
        "            skip2 = tf.concat([debn2_fs, conv2_stride], 3)\r\n",
        "            channels2 = skip2.get_shape().as_list()[3]\r\n",
        "     \r\n",
        "            deconv1_fs = self.new_deconv_layer( skip2, [3,3,32,channels2], conv1_stride.get_shape().as_list(), stride=2, name=\"deconv1_fs\")\r\n",
        "            debn1_fs = tf.nn.elu(deconv1_fs)    \r\n",
        "            \r\n",
        "            skip1 = tf.concat([debn1_fs, conv1_stride], 3)\r\n",
        "            channels1 = skip1.get_shape().as_list()[3]\r\n",
        "        \r\n",
        "            recon = self.new_deconv_layer( skip1, [3,3,3,channels1],  images.get_shape().as_list(), stride=2, name=\"recon\") \r\n",
        "        return recon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKe4nkQ-Bg1i"
      },
      "source": [
        "def discriminator(self, images, is_train, reuse=None):\r\n",
        "        with tf.variable_scope('DIS', reuse=reuse):\r\n",
        "            conv1 = self.new_conv_layer(images, [4,4,3,64], stride=2, name=\"conv1\" )\r\n",
        "            bn1 = self.leaky_relu(self.batchnorm(conv1, is_train, name='bn1'))\r\n",
        "            #bn1 = tf.nn.elu(conv1) \r\n",
        "            conv2 = self.new_conv_layer(bn1, [4,4,64,128], stride=2, name=\"conv2\")\r\n",
        "            bn2 = self.leaky_relu(self.batchnorm(conv2, is_train, name='bn2'))\r\n",
        "            #bn2 = tf.nn.elu(conv2) \r\n",
        "            conv3 = self.new_conv_layer(bn2, [4,4,128,256], stride=2, name=\"conv3\")\r\n",
        "            bn3 = self.leaky_relu(self.batchnorm(conv3, is_train, name='bn3'))\r\n",
        "            #bn3 = tf.nn.elu(conv3) \r\n",
        "            conv4 = self.new_conv_layer(bn3, [4,4,256,512], stride=2, name=\"conv4\")\r\n",
        "            bn4 = self.leaky_relu(self.batchnorm(conv4, is_train, name='bn4'))\r\n",
        "            #bn4 = tf.nn.elu(conv4) \r\n",
        "            output = self.new_fc_layer( bn4, output_size=1, name='output')\r\n",
        "        return output[:,0]       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3DRVTi_a6t2"
      },
      "source": [
        "# Trying with PyTorch\r\n",
        "from __future__ import print_function\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.parallel\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutils\r\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "499cff714e604be89bec523a3ca470f8",
            "fd2f3d8747644583912496275bf35e97",
            "8a0a9758240c4f59832234d789e79947",
            "4a70a80b98a2437d907b7a3a30f2535b",
            "12f64434b7bb43a782ea06df22a46453",
            "bf0a7f412da944448d89a4cfc118affb",
            "b1714f9b863c45859e7280b6a85eae40",
            "54586449cd2d4ce9a9c9795cacdbe9a0"
          ]
        },
        "id": "Bq3AyAk1cjGV",
        "outputId": "65fb916c-6156-4019-9198-16177c246a80"
      },
      "source": [
        "batchSize = 64 \r\n",
        "imageSize = 64 \r\n",
        "\r\n",
        "transform = transforms.Compose([transforms.Resize(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) \r\n",
        "\r\n",
        "dataset = dset.CIFAR10(root = './data', download = True, transform = transform) \r\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "499cff714e604be89bec523a3ca470f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9w85st0cjgf"
      },
      "source": [
        "def weights_init(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find('Conv') != -1:\r\n",
        "        m.weight.data.normal_(0.0, 0.02)\r\n",
        "    elif classname.find('BatchNorm') != -1:\r\n",
        "        m.weight.data.normal_(1.0, 0.02)\r\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJUmOulXcji4"
      },
      "source": [
        "class G(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(G, self).__init__()\r\n",
        "        self.main = nn.Sequential(\r\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\r\n",
        "            nn.BatchNorm2d(512),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(256),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(128),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(64),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\r\n",
        "            nn.Tanh()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output = self.main(input)\r\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBMYCcwZcjla",
        "outputId": "3555ca32-b957-4de5-d963-5eeaa1151014"
      },
      "source": [
        "netG = G()\r\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G(\n",
              "  (main): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (13): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOEwHcoZhQ2G"
      },
      "source": [
        "class D(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(D, self).__init__()\r\n",
        "        self.main = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\r\n",
        "            nn.LeakyReLU(0.2, inplace = True),\r\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(128),\r\n",
        "            nn.LeakyReLU(0.2, inplace = True),\r\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(256),\r\n",
        "            nn.LeakyReLU(0.2, inplace = True),\r\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\r\n",
        "            nn.BatchNorm2d(512),\r\n",
        "            nn.LeakyReLU(0.2, inplace = True),\r\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias = False),\r\n",
        "            nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        output = self.main(input)\r\n",
        "        return output.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXc5X0qzhQ7l",
        "outputId": "5df8f0db-93c3-4e78-8290-5cfc0b8205ab"
      },
      "source": [
        "netD = D()\r\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-72VYyShQ_g"
      },
      "source": [
        "criterion = nn.BCELoss()\r\n",
        "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\r\n",
        "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SJydu53hRCo"
      },
      "source": [
        "for epoch in range(50):\r\n",
        "\r\n",
        "    for i, data in enumerate(dataloader, 0):\r\n",
        "        \r\n",
        "        netD.zero_grad()\r\n",
        "        \r\n",
        "        real, _ = data\r\n",
        "        input = Variable(real)\r\n",
        "        target = Variable(torch.ones(input.size()[0]))\r\n",
        "        output = netD(input)\r\n",
        "        errD_real = criterion(output, target)\r\n",
        "        \r\n",
        "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1))\r\n",
        "        fake = netG(noise)\r\n",
        "        target = Variable(torch.zeros(input.size()[0]))\r\n",
        "        output = netD(fake.detach())\r\n",
        "        errD_fake = criterion(output, target)\r\n",
        "\r\n",
        "        errD = errD_real + errD_fake\r\n",
        "        errD.backward()\r\n",
        "        optimizerD.step()\r\n",
        "\r\n",
        "        netG.zero_grad()\r\n",
        "        target = Variable(torch.ones(input.size()[0]))\r\n",
        "        output = netD(fake)\r\n",
        "        errG = criterion(output, target)\r\n",
        "        errG.backward()\r\n",
        "        optimizerG.step()\r\n",
        "        print('[%d/%d][%d/%d]' % (epoch, 50, i, len(dataloader),))\r\n",
        "        if i % 100 == 0:\r\n",
        "            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\r\n",
        "            fake = netG(noise)\r\n",
        "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
